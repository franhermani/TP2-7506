{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "                             BaggingClassifier, VotingClassifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de entrenamiento y Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('csv_files/modelo_final.csv')\n",
    "test_final = pd.read_csv('csv_files/test_final.csv')\n",
    "#train = pd.read_csv('csv_files/modelo_final_featured.csv')\n",
    "#test_final = pd.read_csv('csv_files/test_final_featured.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las variables categóricas al tipo correspondiente, para reducir el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rango_edad'] = train['rango_edad'].astype('category')\n",
    "train['sexo'] = train['sexo'].astype('category') \n",
    "train['nivel_estudios'] = train['nivel_estudios'].astype('category')\n",
    "train['esta_estudiando'] = train['esta_estudiando'].astype('category')\n",
    "train['tipo_de_trabajo'] = train['tipo_de_trabajo'].astype('category')\n",
    "train['nivel_laboral'] = train['nivel_laboral'].astype('category')\n",
    "train['nombre_zona'] = train['nombre_zona'].astype('category')\n",
    "train['sepostulo'] = train['sepostulo'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['rango_edad'] = test_final['rango_edad'].astype('category')\n",
    "test_final['sexo'] = test_final['sexo'].astype('category') \n",
    "test_final['nivel_estudios'] = test_final['nivel_estudios'].astype('category')\n",
    "test_final['esta_estudiando'] = test_final['esta_estudiando'].astype('category')\n",
    "test_final['tipo_de_trabajo'] = test_final['tipo_de_trabajo'].astype('category')\n",
    "test_final['nivel_laboral'] = test_final['nivel_laboral'].astype('category')\n",
    "test_final['nombre_zona'] = test_final['nombre_zona'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los IDs necesarios para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aviso_postulante = test_final['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el set de entrenamiento y el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>titulo</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>nombre_area</th>\n",
       "      <th>sepostulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288018</th>\n",
       "      <td>1112320305</td>\n",
       "      <td>xkd0kpY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asistente geriátrica y auxiliar de enfermería</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Salud</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808602</th>\n",
       "      <td>1112292828</td>\n",
       "      <td>rmdwz5O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Analista de Recursos Humanos - Formosa</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Recursos Humanos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2148828</th>\n",
       "      <td>1112424032</td>\n",
       "      <td>W9P0RGX</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Asesores de Ventas de Seguros de Vida, Ahorro ...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Ventas</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120430</th>\n",
       "      <td>1111455174</td>\n",
       "      <td>6rBYDGl</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Vendedor viajante Resistencia Chaco.</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Oficios y Profesiones</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994981</th>\n",
       "      <td>1112245051</td>\n",
       "      <td>EeYJaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ingeniero Proyecto - Administración de Contrat...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Control de Gestión</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idaviso idpostulante rango_edad sexo nivel_estudios  \\\n",
       "288018   1112320305      xkd0kpY        1.0    1            2.0   \n",
       "1808602  1112292828      rmdwz5O        1.0    2            2.0   \n",
       "2148828  1112424032      W9P0RGX        3.0    2            4.0   \n",
       "120430   1111455174      6rBYDGl        2.0    1            4.0   \n",
       "2994981  1112245051       EeYJaN        4.0    2            7.0   \n",
       "\n",
       "        esta_estudiando                                             titulo  \\\n",
       "288018              0.0      Asistente geriátrica y auxiliar de enfermería   \n",
       "1808602             0.0             Analista de Recursos Humanos - Formosa   \n",
       "2148828             1.0  Asesores de Ventas de Seguros de Vida, Ahorro ...   \n",
       "120430              0.0               Vendedor viajante Resistencia Chaco.   \n",
       "2994981             1.0  Ingeniero Proyecto - Administración de Contrat...   \n",
       "\n",
       "        tipo_de_trabajo nivel_laboral nombre_zona            nombre_area  \\\n",
       "288018               10             3           3                  Salud   \n",
       "1808602              10             3           3       Recursos Humanos   \n",
       "2148828              10             3           3                 Ventas   \n",
       "120430               10             3           3  Oficios y Profesiones   \n",
       "2994981              10             3           3     Control de Gestión   \n",
       "\n",
       "        sepostulo  \n",
       "288018        0.0  \n",
       "1808602       1.0  \n",
       "2148828       1.0  \n",
       "120430        0.0  \n",
       "2994981       1.0  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 12 columns):\n",
      "idaviso            int64\n",
      "idpostulante       object\n",
      "rango_edad         category\n",
      "sexo               category\n",
      "nivel_estudios     category\n",
      "esta_estudiando    category\n",
      "titulo             object\n",
      "tipo_de_trabajo    category\n",
      "nivel_laboral      category\n",
      "nombre_zona        category\n",
      "nombre_area        object\n",
      "sepostulo          category\n",
      "dtypes: category(8), int64(1), object(3)\n",
      "memory usage: 114.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>sexo</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>titulo</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_area</th>\n",
       "      <th>nombre_empresa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64446</th>\n",
       "      <td>64446</td>\n",
       "      <td>1112458235</td>\n",
       "      <td>0zBq4qM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Administrativo Contable</td>\n",
       "      <td>&lt;p&gt;Importante industria Nacional ubicada en La...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Administración</td>\n",
       "      <td>MAPSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53311</th>\n",
       "      <td>53311</td>\n",
       "      <td>1112444844</td>\n",
       "      <td>E2Rb80</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Analista Contable</td>\n",
       "      <td>&lt;p&gt;Prestigiosa Universidad se encuentra en la ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Administración</td>\n",
       "      <td>Fundación Isalud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53550</th>\n",
       "      <td>53550</td>\n",
       "      <td>1112445282</td>\n",
       "      <td>8WJblL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ASISTENTE ADMINISTRATIVO Jr - Localiza Rent a Car</td>\n",
       "      <td>&lt;p&gt;Localiza Rent a Car, rentadora de vehículos...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Administración</td>\n",
       "      <td>SERVIAUT SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28953</th>\n",
       "      <td>28953</td>\n",
       "      <td>1112367849</td>\n",
       "      <td>ZWxZDZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Liquidador de Sueldos</td>\n",
       "      <td>&lt;p style=\"\"&gt;&lt;strong&gt;&lt;u&gt;&lt;span style=\"\"&gt;Liquidad...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Contabilidad</td>\n",
       "      <td>CARDINAL RRHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18096</th>\n",
       "      <td>18096</td>\n",
       "      <td>1112208757</td>\n",
       "      <td>DrXOmbP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Repositor externo Zona Norte</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Adecco Sales &amp;amp; Marketing&lt;/stron...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Almacén / Depósito / Expedición</td>\n",
       "      <td>Adecco -Sales &amp; Marketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     idaviso idpostulante nivel_estudios esta_estudiando sexo  \\\n",
       "64446  64446  1112458235      0zBq4qM            4.0             1.0    1   \n",
       "53311  53311  1112444844       E2Rb80            4.0             0.0    2   \n",
       "53550  53550  1112445282       8WJblL            4.0             0.0    1   \n",
       "28953  28953  1112367849       ZWxZDZ            4.0             0.0    2   \n",
       "18096  18096  1112208757      DrXOmbP            2.0             0.0    2   \n",
       "\n",
       "      rango_edad                                             titulo  \\\n",
       "64446        1.0                            Administrativo Contable   \n",
       "53311        3.0                                  Analista Contable   \n",
       "53550        2.0  ASISTENTE ADMINISTRATIVO Jr - Localiza Rent a Car   \n",
       "28953        3.0                              Liquidador de Sueldos   \n",
       "18096        1.0                       Repositor externo Zona Norte   \n",
       "\n",
       "                                             descripcion nombre_zona  \\\n",
       "64446  <p>Importante industria Nacional ubicada en La...         3.0   \n",
       "53311  <p>Prestigiosa Universidad se encuentra en la ...         3.0   \n",
       "53550  <p>Localiza Rent a Car, rentadora de vehículos...         3.0   \n",
       "28953  <p style=\"\"><strong><u><span style=\"\">Liquidad...         3.0   \n",
       "18096  <p><strong>Adecco Sales &amp; Marketing</stron...         3.0   \n",
       "\n",
       "      tipo_de_trabajo nivel_laboral                      nombre_area  \\\n",
       "64446            10.0           3.0                   Administración   \n",
       "53311            10.0           2.0                   Administración   \n",
       "53550            10.0           2.0                   Administración   \n",
       "28953            10.0           3.0                     Contabilidad   \n",
       "18096            10.0           3.0  Almacén / Depósito / Expedición   \n",
       "\n",
       "                   nombre_empresa  \n",
       "64446                       MAPSA  \n",
       "53311            Fundación Isalud  \n",
       "53550                SERVIAUT SA   \n",
       "28953               CARDINAL RRHH  \n",
       "18096  Adecco -Sales & Marketing   "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 14 columns):\n",
      "id                 100000 non-null int64\n",
      "idaviso            100000 non-null int64\n",
      "idpostulante       100000 non-null object\n",
      "nivel_estudios     100000 non-null category\n",
      "esta_estudiando    100000 non-null category\n",
      "sexo               100000 non-null category\n",
      "rango_edad         100000 non-null category\n",
      "titulo             95552 non-null object\n",
      "descripcion        95552 non-null object\n",
      "nombre_zona        100000 non-null category\n",
      "tipo_de_trabajo    100000 non-null category\n",
      "nivel_laboral      100000 non-null category\n",
      "nombre_area        95552 non-null object\n",
      "nombre_empresa     95540 non-null object\n",
      "dtypes: category(7), int64(2), object(5)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los features que utilizaremos para los algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features categóricos:\n",
    "f1 = 'rango_edad'\n",
    "f2 = 'sexo'\n",
    "f3 = 'nivel_estudios'\n",
    "f4 = 'esta_estudiando'\n",
    "f5 = 'tipo_de_trabajo'\n",
    "f6 = 'nivel_laboral'\n",
    "f7 = 'nombre_zona'\n",
    "\n",
    "f8 = 'estudios_vs_laboral'\n",
    "f9 = 'estudia_vs_tipo_trabajo'\n",
    "f10 = 'edad_vs_tipo_trabajo'\n",
    "f11 = 'edad_vs_zona'\n",
    "\n",
    "# Features strings:\n",
    "'titulo'\n",
    "'descripcion'\n",
    "'nombre_area'\n",
    "'nombre_empresa'\n",
    "\n",
    "#features = [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f11]\n",
    "features = [f1,f2,f3,f4,f5,f6,f7]\n",
    "#features = [f8,f9,f10,f11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos el set de entrenamiento para realizar pruebas locales de hiper-parámetros antes de realizar cada submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = 0.1\n",
    "random_s = 0\n",
    "\n",
    "x = np.array(train[features])\n",
    "y = np.array(train['sepostulo'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_s, random_state=random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el set de entrenamiento para el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(test_final[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de la Correlación de Pearson entre los distintos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colormap = plt.cm.RdBu\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.title('Features - Correlación de Pearson', y=1.05, size=15)\n",
    "#sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#            square=True, cmap=colormap, linecolor='white', annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos probados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores iniciales para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES INICIALES PARA K')\n",
    "\n",
    "k_valores = [5,10,15]\n",
    "mejor_k = 0\n",
    "mejor_precision = 0\n",
    "\n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k=', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores grid search para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES GRID SEARCH PARA K')\n",
    "\n",
    "k_valores = []\n",
    "\n",
    "for i in range(mejor_k-2, mejor_k+3):\n",
    "    k_valores.append(i)\n",
    "    \n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k =', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos el test final con el mejor k obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejor_k = \n",
    "\n",
    "# Creamos el KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "knn.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = knn.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_knn.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.57179\n",
      "Tiempo de ejecución: 202.23012 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_rf = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':5,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el Random Forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = random_forest.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = random_forest.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = random_forest.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    54465\n",
       "1.0    45535\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_random_forest_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59758\n",
      "1    40242\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.567796\n",
      "Tiempo de ejecución: 37.07304 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_et = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el extra_trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "extra_trees.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = extra_trees.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = extra_trees.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = extra_trees.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_extra_trees.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_extra_trees_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    63879\n",
       "1.0    36121\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59551\n",
      "1    40449\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.520864\n",
      "Tiempo de ejecución: 1.01902 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "naive_bayes.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = naive_bayes.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = naive_bayes.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = naive_bayes.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_naive_bayes.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_naive_bayes_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    59833\n",
       "0    40167\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40167\n",
      "1    59833\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.500252\n",
      "Tiempo de ejecución: 1.45909 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = perceptron.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "perceptron.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = perceptron.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100000\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_perceptron.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_svm = {'C':1.0, 'kernel':'rbf', 'gamma':'auto'}\n",
    "\n",
    "# Creamos el svm\n",
    "svm = SVC(**params_optimos_svm)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = svm.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_svm = {'C':1.0, 'kernel':'rbf', 'gamma':'auto'}\n",
    "\n",
    "# Creamos el svm\n",
    "svm = SVC(**params_optimos_svm)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "svm.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = svm.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_svm.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.529852\n",
      "Tiempo de ejecución: 26.84970 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_ab = {'n_estimators':50}\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "ada_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = ada_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = ada_boost.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = ada_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_ada_boost.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_ada_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50479\n",
       "0    49521\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    49521\n",
      "1    50479\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.579472\n",
      "Tiempo de ejecución: 32.61337 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_gb = {'learning_rate':0.1, 'n_estimators':75, 'max_depth':4, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'subsample':1.0, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "gra_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = gra_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gra_boost.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gra_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_gra_boost.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_gra_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    62205\n",
       "1.0    37795\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    64084\n",
      "1    35916\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.522424\n",
      "Tiempo de ejecución: 3.97218 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "log_reg.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = log_reg.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = log_reg.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_log_reg.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_log_reg_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56324\n",
       "1    43676\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    56324\n",
      "1    43676\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.583244\n",
      "Tiempo de ejecución: 12.45123 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_dt = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "# Creamos el logistic regression\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "decision_tree.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = decision_tree.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = decision_tree.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "\n",
    "submit.to_csv('submits/submit_decision_tree.csv', index=False)\n",
    "submit_proba.to_csv('submits/submit_decision_tree_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    59439\n",
       "1.0    40561\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59821\n",
      "1    40179\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.522968\n",
      "Tiempo de ejecución: 243.49726 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                  'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    56350\n",
       "1    43650\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_bagging_log_reg.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Con Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.53406\n",
      "Tiempo de ejecución: 19.59580 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_dt = {'base_estimator':DecisionTreeClassifier(**params_optimos_dt), 'n_estimators':10, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50858\n",
       "1    49142\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_bagging_decision_tree.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.534204\n",
      "Tiempo de ejecución: 165.94960 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Creamos los estimadores base que utilizaremos para el voting\n",
    "estimador_1 = DecisionTreeClassifier(**params_optimos_dt)\n",
    "estimador_2 = GradientBoostingClassifier(**params_optimos_gb)\n",
    "estimador_3 = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Los agregamos a la lista de estimadores\n",
    "estimadores = []\n",
    "estimadores.append(('Naive Bayes', estimador_1))\n",
    "estimadores.append(('Logistic Regression', estimador_2))\n",
    "estimadores.append(('Random Forest', estimador_3))\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = voting.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "voting.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = voting.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50485\n",
       "1    49515\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_voting.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de algunas variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0] # Cantidad de registros totales del set de entrenamiento\n",
    "\n",
    "ntest = test_final.shape[0] # Cantidad de registros totales del test final\n",
    "\n",
    "SEED = 0 # Seed\n",
    "\n",
    "NFOLDS = 4 # Cantidad de bloques a particionar para KFold\n",
    "\n",
    "kfold = KFold(ntrain, n_folds=NFOLDS, random_state=SEED) # KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la clase SklearnPadre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que realizamos a continuación es la creación de una clase que posee los métodos comunes de los clasificadores de Sklearn que utilizaremos en el presente trabajo. De esta forma, ahorramos líneas de código y evitamos redundancia a la hora de utilizar los métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El inicializador recibe un clasificador de Sklearn, un seed y los parámetros necesarios del clasificador en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnPadre(object):\n",
    "    def __init__(self, clasif, seed=0, parametros=None):\n",
    "        parametros['random_state'] = seed\n",
    "        self.clasif = clasif(**parametros)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clasif.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clasif.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clasif.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self, x, y):\n",
    "        print(self.clasif.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones OOF (Out Of Fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ensamble utiliza predicciones de los clasificadores base como input para el entrenamiento del modelo de 2do nivel. Sin embargo, no podemos entrenar los modelos base con la totalidad del set de entrenamiento. Esto genera el riesgo de que nuestro modelo de 1er nivel conozca el test final y overfitee cuando utilice las predicciones base.\n",
    "\n",
    "Por ello, utilizamos la siguiente función para tomar distintos bloques del set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clasif, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros(ntrain)\n",
    "    oof_test = np.zeros(ntest)\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold):\n",
    "        x_train_i = x_train[train_index]\n",
    "        y_train_i = y_train[train_index]\n",
    "        x_test_i = x_train[test_index]\n",
    "\n",
    "        clasif.train(x_train_i, y_train_i)\n",
    "\n",
    "        oof_train[test_index] = clasif.predict(x_test_i)\n",
    "        oof_test_skf[i, :] = clasif.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    \n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de 1er Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación llevaremos a cabo nuestro primer nivel de clasificación mediante el uso de algunos clasificadores de la librería Sklearn:\n",
    "\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Decision Tree\n",
    "- Gradient Boosting\n",
    "- TO DO: elegir alguno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de los hiper-parámetros necesarios para cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "rf_params = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':15, 'min_samples_split':5,\\\n",
    "             'min_samples_leaf':2, 'bootstrap':True, 'oob_score':False, 'warm_start':True}\n",
    "\n",
    "# EXTRA TREES\n",
    "et_params = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "\n",
    "# DECISION TREE\n",
    "dt_params = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "\n",
    "# GRADIENT BOOSTING\n",
    "gb_params = {'learning_rate':0.1, 'n_estimators':75, 'max_depth':4, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'subsample':1.0, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# TO DO: elegir alguno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los clasificadores según los hiper-parámetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = SklearnPadre(clasif=RandomForestClassifier, seed=SEED, parametros=rf_params)\n",
    "\n",
    "extra_trees = SklearnPadre(clasif=ExtraTreesClassifier, seed=SEED, parametros=et_params)\n",
    "\n",
    "decision_tree = SklearnPadre(clasif=DecisionTreeClassifier, seed=SEED, parametros=dt_params)\n",
    "\n",
    "grad_boost = SklearnPadre(clasif=GradientBoostingClassifier, seed=SEED, parametros=gb_params)\n",
    "\n",
    "# TO DO: elegir alguno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output de los modelos de primer nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realizamos las predicciones para el set de entrenamiento y el test final con OOF. Estos resultados base serán utilizados como input en el modelo de segundo nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_total = time()\n",
    "\n",
    "# Random Forest\n",
    "t0_rf = time()\n",
    "rf_oof_train, rf_oof_test = get_oof(random_forest, x, y, x_test_final)\n",
    "tf_rf = time() - t0_rf\n",
    "print (\"Tiempo de entrenamiento del random forest: %0.5f seconds.\" % tf_rf)\n",
    "\n",
    "# Extra Trees\n",
    "t0_et = time()\n",
    "et_oof_train, et_oof_test = get_oof(extra_trees, x, y, x_test_final)\n",
    "tf_et = time() - t0_et\n",
    "print (\"Tiempo de entrenamiento del extra trees: %0.5f seconds.\" % tf_et)\n",
    "\n",
    "# Decision Tree\n",
    "t0_dt = time()\n",
    "dt_oof_train, dt_oof_test = get_oof(decision_tree, x, y, x_test_final)\n",
    "tf_dt = time() - t0_dt\n",
    "print (\"Tiempo de entrenamiento del decision tree: %0.5f seconds.\" % tf_dt)\n",
    "\n",
    "# Gradient Boosting\n",
    "t0_gb = time()\n",
    "gb_oof_train, gb_oof_test = get_oof(grad_boost, x, y, x_test_final)\n",
    "tf_gb = time() - t0_gb\n",
    "print (\"Tiempo de entrenamiento del gradient boosting: %0.5f seconds.\" % tf_gb)\n",
    "\n",
    "# TO DO: elegir alguno\n",
    "t0_svm = time()\n",
    "svm_oof_train, svm_oof_test = get_oof(svm, x, y, x_test_final)\n",
    "tf_svm = time() - t0_svm\n",
    "print (\"Tiempo de entrenamiento del SVM: %0.5f seconds.\" % tf_svm)\n",
    "\n",
    "# Tiempo total de ejecución\n",
    "tf_total = time() - t0_total\n",
    "print (\"Tiempo total de entrenamiento del modelo de 1er nivel: %0.5f seconds.\" % tf_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de los features en base a los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = random_forest.feature_importances(x,y)\n",
    "\n",
    "et_features = extra_trees.feature_importances(x,y)\n",
    "\n",
    "dt_features = decision_tree.feature_importances(x,y)\n",
    "\n",
    "gb_features = grad_boost.feature_importances(x,y)\n",
    "\n",
    "# TO DO: elegir alguno\n",
    "#svm_features = svm.feature_importances(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACA HAY QUE COPIAR Y PEGAR LA SALIDA DE ARRIBA PERO EN FORMATO ARRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un dataframe con la importancia de cada feature para cada clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "\n",
    "df_features = pd.DataFrame({'Features': features,\\\n",
    "                            'Random Forest': rf_features,\\\n",
    "                            'Extra Trees': et_features,\\\n",
    "                            'Decision Tree': dt_features,\\\n",
    "                            'Gradient Boost': gb_features,\\\n",
    "     # TO DO: elegir alguno                       'SVM': svm_features\\\n",
    "                            })\n",
    "\n",
    "df_features = df_features[['Features', 'Random Forest', 'Extra Trees', 'Decision Tree', 'Gradient Boost', 'SVM']]\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: plotear el df de arriba. Podría ser un heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos una columna contenedora del promedio de la importancia del feature para todos los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['promedio'] = df_features.mean(axis=1)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de 2do Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos las predicciones obtenidas en el modelo de primer nivel como input del siguiente modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, analizamos las predicciones del primer nivel para cada clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_primer_nivel = pd.DataFrame({'Random Forest': rf_oof_train.ravel(),\\\n",
    "                                          'Extra Trees': et_oof_train.ravel(),\\\n",
    "                                          'Decision Tree': dt_oof_train.ravel(),\\\n",
    "                                          'Gradient Boosting': gb_oof_train.ravel(),\\\n",
    " # TO DO: elegir alguno                                         'SVM':svm_oof_train.ravel()\\\n",
    "                                          })\n",
    "predicciones_primer_nivel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación de los clasificadores del modelo de 1er nivel (set de entrenamiento del modelo de 2do nivel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: tirar un heatmap con predicciones_primer_nivel.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos las predicciones obtenidas en el modelo de 1er nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2do_nivel = np.concatenate((et_oof_train, rf_oof_train, ab_oof_train, gb_oof_train, svm_oof_train), axis=1)\n",
    "\n",
    "x_test_final_2do_nivel = np.concatenate((et_oof_test, rf_oof_test, ab_oof_test, gb_oof_test, svm_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos XGBoost para el modelo de 2do nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con el set de entrenamiento obtenido en el modelo de 1er nivel\n",
    "xgboost.fit(x_2do_nivel, y)\n",
    "\n",
    "# Realizamos las predicciones con el set definitivo\n",
    "pred_final = gbm.predict(x_test_final_2do_nivel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_ensamble.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
