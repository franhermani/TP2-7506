{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariano/ENTER/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "                             BaggingClassifier, VotingClassifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de entrenamiento y Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('csv_files/modelo_final_featured.csv')\n",
    "test_final = pd.read_csv('csv_files/test_final_featured.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las variables categóricas al tipo correspondiente, para reducir el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rango_edad'] = train['rango_edad'].astype('category')\n",
    "train['sexo'] = train['sexo'].astype('category') \n",
    "train['nivel_estudios'] = train['nivel_estudios'].astype('category')\n",
    "train['esta_estudiando'] = train['esta_estudiando'].astype('category')\n",
    "train['tipo_de_trabajo'] = train['tipo_de_trabajo'].astype('category')\n",
    "train['nivel_laboral'] = train['nivel_laboral'].astype('category')\n",
    "train['nombre_zona'] = train['nombre_zona'].astype('category')\n",
    "train['num_area'] = train['num_area'].astype('category')\n",
    "train['post_por_nivel'] = train['post_por_nivel'].astype('category')\n",
    "train['sepostulo'] = train['sepostulo'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['rango_edad'] = test_final['rango_edad'].astype('category')\n",
    "test_final['sexo'] = test_final['sexo'].astype('category') \n",
    "test_final['nivel_estudios'] = test_final['nivel_estudios'].astype('category')\n",
    "test_final['esta_estudiando'] = test_final['esta_estudiando'].astype('category')\n",
    "test_final['tipo_de_trabajo'] = test_final['tipo_de_trabajo'].astype('category')\n",
    "test_final['nivel_laboral'] = test_final['nivel_laboral'].astype('category')\n",
    "test_final['nombre_zona'] = test_final['nombre_zona'].astype('category')\n",
    "test_final['num_area'] = test_final['num_area'].astype('category')\n",
    "test_final['post_por_nivel'] = test_final['post_por_nivel'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los IDs necesarios para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aviso_postulante = test_final['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el set de entrenamiento y el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>descripcion</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>nombre_area</th>\n",
       "      <th>sepostulo</th>\n",
       "      <th>num_area</th>\n",
       "      <th>post_por_nivel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221898</th>\n",
       "      <td>1112466773</td>\n",
       "      <td>aDjY2W</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;¿Buscas un trabajo de 6 horas? ¿Queres trab...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930977</th>\n",
       "      <td>1112357563</td>\n",
       "      <td>PmVW14Y</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;Seleccionamos  Asesores Comerciales / Vende...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Salud</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667706</th>\n",
       "      <td>1112359648</td>\n",
       "      <td>pzYWlpr</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;En Atos Argentina, empresa líder en servici...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Ventas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496382</th>\n",
       "      <td>1112218738</td>\n",
       "      <td>1BQJpN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>&lt;p&gt;Nos encontramos en la búsqueda de un&lt;strong...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Análisis Funcional</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713299</th>\n",
       "      <td>1112452567</td>\n",
       "      <td>Bm5wjrz</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;Importante Empresa Autopartista se encuentr...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Recursos Humanos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idaviso idpostulante rango_edad sexo nivel_estudios  \\\n",
       "221898  1112466773       aDjY2W        4.0    1            4.0   \n",
       "930977  1112357563      PmVW14Y        3.0    1            4.0   \n",
       "667706  1112359648      pzYWlpr        4.0    2            6.0   \n",
       "496382  1112218738       1BQJpN        4.0    2            2.0   \n",
       "713299  1112452567      Bm5wjrz        2.0    1            4.0   \n",
       "\n",
       "       esta_estudiando                                        descripcion  \\\n",
       "221898             0.0  <p>¿Buscas un trabajo de 6 horas? ¿Queres trab...   \n",
       "930977             0.0  <p>Seleccionamos  Asesores Comerciales / Vende...   \n",
       "667706             0.0  <p>En Atos Argentina, empresa líder en servici...   \n",
       "496382             0.0  <p>Nos encontramos en la búsqueda de un<strong...   \n",
       "713299             1.0  <p>Importante Empresa Autopartista se encuentr...   \n",
       "\n",
       "       tipo_de_trabajo nivel_laboral nombre_zona         nombre_area  \\\n",
       "221898               9             1           3         Call Center   \n",
       "930977              10             3           3               Salud   \n",
       "667706              10             3           3              Ventas   \n",
       "496382              10             3           3  Análisis Funcional   \n",
       "713299              10             3           3    Recursos Humanos   \n",
       "\n",
       "       sepostulo num_area post_por_nivel  \n",
       "221898       0.0      4.0            0.0  \n",
       "930977       1.0     19.0           75.0  \n",
       "667706       1.0      2.0            8.0  \n",
       "496382       0.0     17.0           18.0  \n",
       "713299       1.0      8.0           58.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 14 columns):\n",
      "idaviso            1000000 non-null int64\n",
      "idpostulante       1000000 non-null object\n",
      "rango_edad         1000000 non-null category\n",
      "sexo               1000000 non-null category\n",
      "nivel_estudios     1000000 non-null category\n",
      "esta_estudiando    1000000 non-null category\n",
      "descripcion        1000000 non-null object\n",
      "tipo_de_trabajo    1000000 non-null category\n",
      "nivel_laboral      1000000 non-null category\n",
      "nombre_zona        1000000 non-null category\n",
      "nombre_area        1000000 non-null object\n",
      "sepostulo          1000000 non-null category\n",
      "num_area           1000000 non-null category\n",
      "post_por_nivel     1000000 non-null category\n",
      "dtypes: category(10), int64(1), object(3)\n",
      "memory usage: 41.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>titulo</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>nombre_area</th>\n",
       "      <th>num_area</th>\n",
       "      <th>post_por_nivel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87499</th>\n",
       "      <td>87499</td>\n",
       "      <td>1112466838</td>\n",
       "      <td>Nz05OL4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Responsable de Canales</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8745</th>\n",
       "      <td>8745</td>\n",
       "      <td>1111791687</td>\n",
       "      <td>lDLoKj2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ayudante de cocina/camarero  eventuales,  la m...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Gastronomia</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14182</th>\n",
       "      <td>14182</td>\n",
       "      <td>1112094756</td>\n",
       "      <td>xka8kpK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Representante de Atencion al Cliente/ Banco</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95036</th>\n",
       "      <td>95036</td>\n",
       "      <td>1112487050</td>\n",
       "      <td>5ozmXz</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Administrativo de Logística Eventual -  CABA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Logística</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20476</th>\n",
       "      <td>20476</td>\n",
       "      <td>1112256641</td>\n",
       "      <td>ZR0YJb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OPERARIO de BALANCINES Zona Lomas de Zamora GB...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Producción</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     idaviso idpostulante rango_edad sexo nivel_estudios  \\\n",
       "87499  87499  1112466838      Nz05OL4        1.0  2.0            4.0   \n",
       "8745    8745  1111791687      lDLoKj2        1.0  2.0            1.0   \n",
       "14182  14182  1112094756      xka8kpK        2.0  2.0            2.0   \n",
       "95036  95036  1112487050       5ozmXz        2.0  1.0            4.0   \n",
       "20476  20476  1112256641       ZR0YJb        3.0  1.0            4.0   \n",
       "\n",
       "      esta_estudiando                                             titulo  \\\n",
       "87499             1.0                             Responsable de Canales   \n",
       "8745              0.0  ayudante de cocina/camarero  eventuales,  la m...   \n",
       "14182             0.0        Representante de Atencion al Cliente/ Banco   \n",
       "95036             1.0       Administrativo de Logística Eventual -  CABA   \n",
       "20476             0.0  OPERARIO de BALANCINES Zona Lomas de Zamora GB...   \n",
       "\n",
       "      tipo_de_trabajo nivel_laboral nombre_zona  nombre_area num_area  \\\n",
       "87499            10.0           4.0         3.0    Comercial      2.0   \n",
       "8745              7.0           2.0         3.0  Gastronomia      9.0   \n",
       "14182             9.0           3.0         3.0  Call Center      4.0   \n",
       "95036            10.0           3.0         3.0    Logística     11.0   \n",
       "20476            10.0           3.0         3.0   Producción      3.0   \n",
       "\n",
       "      post_por_nivel  \n",
       "87499            2.0  \n",
       "8745             7.0  \n",
       "14182           24.0  \n",
       "95036            4.0  \n",
       "20476            0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 14 columns):\n",
      "id                 100000 non-null int64\n",
      "idaviso            100000 non-null int64\n",
      "idpostulante       100000 non-null object\n",
      "rango_edad         100000 non-null category\n",
      "sexo               100000 non-null category\n",
      "nivel_estudios     100000 non-null category\n",
      "esta_estudiando    100000 non-null category\n",
      "titulo             100000 non-null object\n",
      "tipo_de_trabajo    100000 non-null category\n",
      "nivel_laboral      100000 non-null category\n",
      "nombre_zona        100000 non-null category\n",
      "nombre_area        100000 non-null object\n",
      "num_area           100000 non-null category\n",
      "post_por_nivel     100000 non-null category\n",
      "dtypes: category(9), int64(2), object(3)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los features que utilizaremos para los algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "f1 = 'rango_edad'\n",
    "f2 = 'sexo'\n",
    "f3 = 'nivel_estudios'\n",
    "f4 = 'esta_estudiando'\n",
    "f5 = 'tipo_de_trabajo'\n",
    "f6 = 'nivel_laboral'\n",
    "f7 = 'nombre_zona'\n",
    "f8 = 'num_area'\n",
    "f9 = 'post_por_nivel'\n",
    "\n",
    "features = [f1,f2,f3,f4,f5,f6,f8,f9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos el set de entrenamiento para realizar pruebas locales de hiper-parámetros antes de realizar cada submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = 0.25\n",
    "random_s = 0\n",
    "\n",
    "x = np.array(train[features])\n",
    "y = np.array(train['sepostulo'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_s, random_state=random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el set de entrenamiento para el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(test_final[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos probados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores iniciales para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES INICIALES PARA K\n",
      "La precisión para k= 5 es: 0.815804\n",
      "La precisión para k= 10 es: 0.82326\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES INICIALES PARA K')\n",
    "\n",
    "k_valores = [5,10,20,30,40,50]\n",
    "mejor_k = 0\n",
    "mejor_precision = 0\n",
    "\n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k=', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores grid search para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES GRID SEARCH PARA K')\n",
    "\n",
    "k_valores = []\n",
    "\n",
    "for i in range(mejor_k-2, mejor_k+3):\n",
    "    k_valores.append(i)\n",
    "    \n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k =', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos el test final con el mejor k obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "knn.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = knn.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits/submit_knn.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.789756\n",
      "Tiempo de ejecución: 32.18067 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_rf = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el Random Forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = random_forest.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 45.83240 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = random_forest.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 39.08275 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = random_forest.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_random_forest_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.671444\n",
      "Tiempo de ejecución: 32.77066 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_et = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el extra_trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "extra_trees.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = extra_trees.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 43.61266 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = extra_trees.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 43.21765 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = extra_trees.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_extra_trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_extra_trees_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.636404\n",
      "Tiempo de ejecución: 0.83910 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "naive_bayes.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = naive_bayes.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 0.45636 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = naive_bayes.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 0.45705 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = naive_bayes.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_naive_bayes_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.787664\n",
      "Tiempo de ejecución: 1.27687 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = perceptron.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 1.23521 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "perceptron.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = perceptron.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_perceptron.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.820452\n",
      "Tiempo de ejecución: 31.23796 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_ab = {'n_estimators':50}\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "ada_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = ada_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = ada_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 35.58527 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = ada_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_ada_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_ada_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.824944\n",
      "Tiempo de ejecución: 35.10870 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_gb = {'learning_rate':0.1, 'n_estimators':75, 'max_depth':4, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'subsample':0.5, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "gra_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = gra_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gra_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 41.68665 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gra_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_gra_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_gra_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.759756\n",
      "Tiempo de ejecución: 6.67571 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "log_reg.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 6.19293 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = log_reg.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 6.12622 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = log_reg.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_log_reg_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.823076\n",
      "Tiempo de ejecución: 247.43929 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_dt = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "# Creamos el logistic regression\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "decision_tree.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 469.61542 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = decision_tree.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 461.34604 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = decision_tree.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_decision_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_decision_tree_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.758236\n",
      "Tiempo de ejecución: 405.60441 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 388.88411 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 371.44975 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_bagging_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_bagging_log_reg_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Con Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.83458\n",
      "Tiempo de ejecución: 708.82964 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_dt = {'base_estimator':DecisionTreeClassifier(**params_optimos_dt), 'n_estimators':10, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c66a21de3cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Lo entrenamos con la totalidad del set de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbagging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Predecimos las postulaciones del set final\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 375\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Draw samples, using a mask, and then fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ENTER/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 920.67132 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_bagging_decision_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_bagging_decision_tree_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los estimadores base que utilizaremos para el voting\n",
    "estimador_1 = DecisionTreeClassifier(**params_optimos_dt)\n",
    "estimador_2 = GradientBoostingClassifier(**params_optimos_gb)\n",
    "estimador_3 = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Los agregamos a la lista de estimadores\n",
    "estimadores = []\n",
    "estimadores.append(('Naive Bayes', estimador_1))\n",
    "estimadores.append(('Logistic Regression', estimador_2))\n",
    "estimadores.append(('Random Forest', estimador_3))\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = voting.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "voting.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = voting.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "xgboost.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred_final = xgboost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred_final)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = xgboost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = xgboost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_xgboost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
