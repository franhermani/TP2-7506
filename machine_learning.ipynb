{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier,\\\n",
    "                             BaggingClassifier, VotingClassifier)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de entrenamiento y Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los archivos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('csv_files/modelo_final.csv')\n",
    "test_final = pd.read_csv('csv_files/test_final.csv')\n",
    "#train = pd.read_csv('csv_files/modelo_final_featured.csv')\n",
    "#test_final = pd.read_csv('csv_files/test_final_featured.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos las variables categóricas al tipo correspondiente, para reducir el uso de memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['rango_edad'] = train['rango_edad'].astype('category')\n",
    "train['sexo'] = train['sexo'].astype('category') \n",
    "train['nivel_estudios'] = train['nivel_estudios'].astype('category')\n",
    "train['esta_estudiando'] = train['esta_estudiando'].astype('category')\n",
    "train['tipo_de_trabajo'] = train['tipo_de_trabajo'].astype('category')\n",
    "train['nivel_laboral'] = train['nivel_laboral'].astype('category')\n",
    "train['nombre_zona'] = train['nombre_zona'].astype('category')\n",
    "train['sepostulo'] = train['sepostulo'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final['rango_edad'] = test_final['rango_edad'].astype('category')\n",
    "test_final['sexo'] = test_final['sexo'].astype('category') \n",
    "test_final['nivel_estudios'] = test_final['nivel_estudios'].astype('category')\n",
    "test_final['esta_estudiando'] = test_final['esta_estudiando'].astype('category')\n",
    "test_final['tipo_de_trabajo'] = test_final['tipo_de_trabajo'].astype('category')\n",
    "test_final['nivel_laboral'] = test_final['nivel_laboral'].astype('category')\n",
    "test_final['nombre_zona'] = test_final['nombre_zona'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los IDs necesarios para el submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aviso_postulante = test_final['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos el set de entrenamiento y el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>titulo</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>nombre_area</th>\n",
       "      <th>sepostulo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581813</th>\n",
       "      <td>1112502573</td>\n",
       "      <td>W9PMM6X</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chef pastelero y pizzero p/ trabajar en España.</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Gastronomia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965707</th>\n",
       "      <td>1112206678</td>\n",
       "      <td>kPjKMLb</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Programa Jóvenes Emprendedores 2018</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Producción</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383017</th>\n",
       "      <td>1112443958</td>\n",
       "      <td>OqeMABv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Asesor Comercial Call center - MICROCENTRO</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Ventas</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1898158</th>\n",
       "      <td>1112204681</td>\n",
       "      <td>ZDaKjK8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Asesor/a de Belleza - Part Time</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Comercial</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213585</th>\n",
       "      <td>1112140003</td>\n",
       "      <td>akjERAZ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Coordinador de Asistencia Vehicular</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idaviso idpostulante rango_edad sexo nivel_estudios  \\\n",
       "581813   1112502573      W9PMM6X        4.0    1            3.0   \n",
       "2965707  1112206678      kPjKMLb        1.0    2            2.0   \n",
       "2383017  1112443958      OqeMABv        2.0    1            4.0   \n",
       "1898158  1112204681      ZDaKjK8        2.0    2            3.0   \n",
       "213585   1112140003      akjERAZ        1.0    2            4.0   \n",
       "\n",
       "        esta_estudiando                                            titulo  \\\n",
       "581813              0.0  Chef pastelero y pizzero p/ trabajar en España.    \n",
       "2965707             0.0               Programa Jóvenes Emprendedores 2018   \n",
       "2383017             1.0        Asesor Comercial Call center - MICROCENTRO   \n",
       "1898158             1.0                  Asesor/a de Belleza - Part Time    \n",
       "213585              1.0               Coordinador de Asistencia Vehicular   \n",
       "\n",
       "        tipo_de_trabajo nivel_laboral nombre_zona  nombre_area sepostulo  \n",
       "581813               10             1           3  Gastronomia       0.0  \n",
       "2965707              10             3           3   Producción       1.0  \n",
       "2383017               9             3           3       Ventas       1.0  \n",
       "1898158               9             3           3    Comercial       1.0  \n",
       "213585               10             3           3  Call Center       0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000000 entries, 0 to 2999999\n",
      "Data columns (total 12 columns):\n",
      "idaviso            int64\n",
      "idpostulante       object\n",
      "rango_edad         category\n",
      "sexo               category\n",
      "nivel_estudios     category\n",
      "esta_estudiando    category\n",
      "titulo             object\n",
      "tipo_de_trabajo    category\n",
      "nivel_laboral      category\n",
      "nombre_zona        category\n",
      "nombre_area        object\n",
      "sepostulo          category\n",
      "dtypes: category(8), int64(1), object(3)\n",
      "memory usage: 114.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>idaviso</th>\n",
       "      <th>idpostulante</th>\n",
       "      <th>rango_edad</th>\n",
       "      <th>sexo</th>\n",
       "      <th>nivel_estudios</th>\n",
       "      <th>esta_estudiando</th>\n",
       "      <th>titulo</th>\n",
       "      <th>tipo_de_trabajo</th>\n",
       "      <th>nivel_laboral</th>\n",
       "      <th>nombre_zona</th>\n",
       "      <th>nombre_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1577</td>\n",
       "      <td>1110915410</td>\n",
       "      <td>6voRmO</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAJERAS Y REPOSITORES -  PART TIME</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Tesorería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97540</th>\n",
       "      <td>97540</td>\n",
       "      <td>1112501628</td>\n",
       "      <td>14YNxQ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Atencion al Cliente</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Atención al Cliente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21286</th>\n",
       "      <td>21286</td>\n",
       "      <td>1112272884</td>\n",
       "      <td>aJoO40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Estudiantes de Cs. Económicas- Full Time</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Administración</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24635</th>\n",
       "      <td>24635</td>\n",
       "      <td>1112320618</td>\n",
       "      <td>EEAB58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Playero - Vendedor dual Zona Sur (Eventual)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Transporte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>1473</td>\n",
       "      <td>1110787671</td>\n",
       "      <td>aXRMDZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Con o sin experiencia - Turno mañana - Call ce...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Call Center</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     idaviso idpostulante rango_edad sexo nivel_estudios  \\\n",
       "1577    1577  1110915410       6voRmO        3.0  1.0            4.0   \n",
       "97540  97540  1112501628       14YNxQ        3.0  1.0            4.0   \n",
       "21286  21286  1112272884       aJoO40        3.0  2.0            4.0   \n",
       "24635  24635  1112320618       EEAB58        3.0  2.0            5.0   \n",
       "1473    1473  1110787671       aXRMDZ        4.0  1.0            4.0   \n",
       "\n",
       "      esta_estudiando                                             titulo  \\\n",
       "1577              0.0                 CAJERAS Y REPOSITORES -  PART TIME   \n",
       "97540             1.0                                Atencion al Cliente   \n",
       "21286             1.0           Estudiantes de Cs. Económicas- Full Time   \n",
       "24635             0.0        Playero - Vendedor dual Zona Sur (Eventual)   \n",
       "1473              0.0  Con o sin experiencia - Turno mañana - Call ce...   \n",
       "\n",
       "      tipo_de_trabajo nivel_laboral nombre_zona          nombre_area  \n",
       "1577              9.0           1.0         3.0            Tesorería  \n",
       "97540            10.0           2.0         3.0  Atención al Cliente  \n",
       "21286            10.0           3.0         3.0       Administración  \n",
       "24635            10.0           2.0         3.0           Transporte  \n",
       "1473              9.0           3.0         3.0          Call Center  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "id                 100000 non-null int64\n",
      "idaviso            100000 non-null int64\n",
      "idpostulante       100000 non-null object\n",
      "rango_edad         100000 non-null category\n",
      "sexo               100000 non-null category\n",
      "nivel_estudios     100000 non-null category\n",
      "esta_estudiando    100000 non-null category\n",
      "titulo             95552 non-null object\n",
      "tipo_de_trabajo    100000 non-null category\n",
      "nivel_laboral      100000 non-null category\n",
      "nombre_zona        100000 non-null category\n",
      "nombre_area        95552 non-null object\n",
      "dtypes: category(7), int64(2), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos guardamos los features que utilizaremos para los algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features categóricos:\n",
    "f1 = 'rango_edad'\n",
    "f2 = 'sexo'\n",
    "f3 = 'nivel_estudios'\n",
    "f4 = 'esta_estudiando'\n",
    "f5 = 'tipo_de_trabajo'\n",
    "f6 = 'nivel_laboral'\n",
    "f7 = 'nombre_zona'\n",
    "\n",
    "f8 = 'estudios_vs_laboral'\n",
    "f9 = 'estudia_vs_tipo_trabajo'\n",
    "f10 = 'edad_vs_tipo_trabajo'\n",
    "f11 = 'edad_vs_zona'\n",
    "\n",
    "# Features strings:\n",
    "'titulo'\n",
    "'descripcion'\n",
    "'nombre_area'\n",
    "'nombre_empresa'\n",
    "\n",
    "#features = [f1,f2,f3,f4,f5,f6,f7,f8,f9,f10]\n",
    "features = [f1,f2,f3,f4,f5,f6,f7]\n",
    "#features = [f8,f9,f10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionamos el set de entrenamiento para realizar pruebas locales de hiper-parámetros antes de realizar cada submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_s = 0.25\n",
    "random_s = 0\n",
    "\n",
    "x = np.array(train[features])\n",
    "y = np.array(train['sepostulo'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_s, random_state=random_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el set de entrenamiento para el test final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_final = np.array(test_final[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de la Correlación de Pearson entre los distintos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colormap = plt.cm.RdBu\n",
    "#plt.figure(figsize=(10,10))\n",
    "#plt.title('Features - Correlación de Pearson', y=1.05, size=15)\n",
    "#sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#            square=True, cmap=colormap, linecolor='white', annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos probados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores iniciales para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES INICIALES PARA K')\n",
    "\n",
    "k_valores = [5,10,15]\n",
    "mejor_k = 0\n",
    "mejor_precision = 0\n",
    "\n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k=', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores grid search para K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "print('VALORES GRID SEARCH PARA K')\n",
    "\n",
    "k_valores = []\n",
    "\n",
    "for i in range(mejor_k-2, mejor_k+3):\n",
    "    k_valores.append(i)\n",
    "    \n",
    "for k in k_valores:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    pred = knn.predict(x_test)\n",
    "    precision = accuracy_score(y_test, pred)\n",
    "    print('La precisión para k =', k, 'es:',precision)\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_k = k\n",
    "        \n",
    "print('Con k=', mejor_k, 'se obtuvo la mayor precisión:', mejor_precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predecimos el test final con el mejor k obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejor_k = \n",
    "\n",
    "# Creamos el KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=mejor_k)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "knn.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = knn.predict(x_test_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submits\\submit_knn.csv', index=False)\n",
    "\n",
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5675546666666667\n",
      "Tiempo de ejecución: 77.92498 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_rf = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':5,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el Random Forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "random_forest.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = random_forest.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = random_forest.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el random forest\n",
    "random_forest = RandomForestClassifier(**params_optimos_rf)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "random_forest.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = random_forest.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    54465\n",
       "1.0    45535\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_random_forest_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    70344\n",
      "1    29656\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extra Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.567796\n",
      "Tiempo de ejecución: 37.07304 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_et = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "# Creamos el extra_trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "extra_trees.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = extra_trees.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = extra_trees.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el extra trees\n",
    "extra_trees = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "extra_trees.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = extra_trees.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_extra_trees.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    63879\n",
       "1.0    36121\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_extra_trees_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59551\n",
      "1    40449\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.520864\n",
      "Tiempo de ejecución: 1.01902 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "naive_bayes.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = naive_bayes.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = naive_bayes.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el naive bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "naive_bayes.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = naive_bayes.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    59833\n",
       "0    40167\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_naive_bayes_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40167\n",
      "1    59833\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.4974306666666667\n",
      "Tiempo de ejecución: 4.24587 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "perceptron.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = perceptron.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 4.36965 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "perceptron.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = perceptron.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits\\submit_perceptron.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    98528\n",
       "1.0     1472\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5726546666666666\n",
      "Tiempo de ejecución: 120.72412 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_ab = {'n_estimators':50}\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "ada_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = ada_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 142.45385 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = ada_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el adaptive boosting\n",
    "ada_boost = AdaBoostClassifier(**params_optimos_ab)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "ada_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = ada_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_ada_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    62078\n",
       "1.0    37922\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_ada_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    62078\n",
      "1    37922\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.579472\n",
      "Tiempo de ejecución: 32.61337 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_gb = {'learning_rate':0.1, 'n_estimators':75, 'max_depth':4, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'subsample':1.0, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "gra_boost.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = gra_boost.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gra_boost.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el gradient boosting\n",
    "gra_boost = GradientBoostingClassifier(**params_optimos_gb)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "gra_boost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gra_boost.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_gra_boost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    62205\n",
       "1.0    37795\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_gra_boost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    64084\n",
      "1    35916\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.522424\n",
      "Tiempo de ejecución: 3.97218 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "log_reg.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = log_reg.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 24.91830 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = log_reg.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 24.50829 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el logistic regression\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "log_reg.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = log_reg.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    50846\n",
       "1.0    49154\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_log_reg_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50846\n",
      "1    49154\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5830533333333333\n",
      "Tiempo de ejecución: 129.80762 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_dt = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "                     'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "# Creamos el logistic regression\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "decision_tree.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = decision_tree.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 173.29005 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = decision_tree.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 174.04566 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el decision tree\n",
    "decision_tree = DecisionTreeClassifier(**params_optimos_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "decision_tree.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = decision_tree.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_decision_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    59603\n",
       "1.0    40397\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_decision_tree_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    61458\n",
      "1    38542\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5466626666666666\n",
      "Tiempo de ejecución: 690.49921 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_lr = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train,y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 742.50723 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 741.90100 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_lr)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_bagging_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    56478\n",
       "1.0    43522\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_bagging_log_reg_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    56129\n",
      "1    43871\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Con Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5824866666666667\n",
      "Tiempo de ejecución: 221.12992 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Parámetros óptimos\n",
    "params_optimos_bag_dt = {'base_estimator':DecisionTreeClassifier(**params_optimos_dt), 'n_estimators':10, 'bootstrap':True,\\\n",
    "                         'bootstrap_features':True, 'oob_score':True, 'warm_start':False}\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "bagging.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = bagging.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 251.87817 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = bagging.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 185.18573 seconds.\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el bagging\n",
    "bagging = BaggingClassifier(**params_optimos_bag_dt)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "bagging.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = bagging.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_bagging_decision_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    62153\n",
       "1.0    37847\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_bagging_decision_tree_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    64257\n",
      "1    35743\n",
      "Name: sepostulo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los estimadores base que utilizaremos para el voting\n",
    "estimador_1 = DecisionTreeClassifier(**params_optimos_dt)\n",
    "estimador_2 = GradientBoostingClassifier(**params_optimos_gb)\n",
    "estimador_3 = ExtraTreesClassifier(**params_optimos_et)\n",
    "\n",
    "# Los agregamos a la lista de estimadores\n",
    "estimadores = []\n",
    "estimadores.append(('Naive Bayes', estimador_1))\n",
    "estimadores.append(('Logistic Regression', estimador_2))\n",
    "estimadores.append(('Random Forest', estimador_3))\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "voting.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred = voting.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución: 349.18528 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Francisco\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el voting\n",
    "voting = VotingClassifier(estimators=estimadores)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "voting.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = voting.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    59345\n",
       "1.0    40655\n",
       "Name: sepostulo, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con nuestro set de entrenamiento\n",
    "xgboost.fit(x_train, y_train)\n",
    "\n",
    "# Predecimos valores de nuestro set de datos\n",
    "pred_final = gbm.predict(x_test)\n",
    "\n",
    "# Evaluamos la precisión\n",
    "precision = accuracy_score(y_test, pred)\n",
    "\n",
    "print(\"Precisión: \", precision)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final = gbm.predict(x_test_final)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con la totalidad del set de datos\n",
    "xgboost.fit(x,y)\n",
    "\n",
    "# Predecimos las postulaciones del set final\n",
    "pred_final_proba = gbm.predict_proba(x_test_final)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_xgboost_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Ensamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición de algunas variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0] # Cantidad de registros totales del set de entrenamiento\n",
    "\n",
    "ntest = test_final.shape[0] # Cantidad de registros totales del test final\n",
    "\n",
    "SEED = 0 # Seed\n",
    "\n",
    "NFOLDS = 4 # Cantidad de bloques a particionar para KFold\n",
    "\n",
    "kfold = KFold(ntrain, n_folds=NFOLDS, random_state=SEED) # KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de la clase SklearnPadre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que realizamos a continuación es la creación de una clase que posee los métodos comunes de los clasificadores de Sklearn que utilizaremos en el presente trabajo. De esta forma, ahorramos líneas de código y evitamos redundancia a la hora de utilizar los métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El inicializador recibe un clasificador de Sklearn, un seed y los parámetros necesarios del clasificador en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnPadre(object):\n",
    "    def __init__(self, clasif, seed=0, parametros=None):\n",
    "        parametros['random_state'] = seed\n",
    "        self.clasif = clasif(**parametros)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clasif.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clasif.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clasif.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self, x, y):\n",
    "        print(self.clasif.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones OOF (Out Of Fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ensamble utiliza predicciones de los clasificadores base como input para el entrenamiento del modelo de 2do nivel. Sin embargo, no podemos entrenar los modelos base con la totalidad del set de entrenamiento. Esto genera el riesgo de que nuestro modelo de 1er nivel conozca el test final y overfitee cuando utilice las predicciones base.\n",
    "\n",
    "Por ello, utilizamos la siguiente función para tomar distintos bloques del set de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clasif, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros(ntrain)\n",
    "    oof_test = np.zeros(ntest)\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold):\n",
    "        x_train_i = x_train[train_index]\n",
    "        y_train_i = y_train[train_index]\n",
    "        x_test_i = x_train[test_index]\n",
    "\n",
    "        clasif.train(x_train_i, y_train_i)\n",
    "\n",
    "        oof_train[test_index] = clasif.predict(x_test_i)\n",
    "        oof_test_skf[i, :] = clasif.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    \n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de 1er Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación llevaremos a cabo nuestro primer nivel de clasificación mediante el uso de algunos clasificadores de la librería Sklearn:\n",
    "\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Decision Tree\n",
    "- Gradient Boosting\n",
    "- Bagging con Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de los hiper-parámetros necesarios para cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "rf_params = {'n_estimators':50, 'max_features':'sqrt', 'max_depth':15, 'min_samples_split':5,\\\n",
    "             'min_samples_leaf':2, 'bootstrap':True, 'oob_score':False, 'warm_start':True}\n",
    "\n",
    "# EXTRA TREES\n",
    "et_params = {'n_estimators':100, 'max_features':'sqrt', 'max_depth':5, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'bootstrap':True, 'oob_score':True, 'warm_start':True}\n",
    "\n",
    "\n",
    "# DECISION TREE\n",
    "dt_params = {'criterion':'entropy', 'splitter':'best', 'max_depth':None, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'max_features':'sqrt', 'presort':True}\n",
    "\n",
    "\n",
    "# GRADIENT BOOSTING\n",
    "gb_params = {'learning_rate':0.1, 'n_estimators':75, 'max_depth':4, 'min_samples_split':2,\\\n",
    "             'min_samples_leaf':2, 'subsample':1.0, 'max_features':'sqrt', 'warm_start':True}\n",
    "\n",
    "# BAGGING CON LOGISTIC REGRESSION\n",
    "bag_params = {'base_estimator':LogisticRegression(), 'n_estimators':100, 'bootstrap':True,\\\n",
    "              'bootstrap_features':True, 'oob_score':True, 'warm_start':False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los clasificadores según los hiper-parámetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = SklearnPadre(clasif=RandomForestClassifier, seed=SEED, parametros=rf_params)\n",
    "\n",
    "extra_trees = SklearnPadre(clasif=ExtraTreesClassifier, seed=SEED, parametros=et_params)\n",
    "\n",
    "decision_tree = SklearnPadre(clasif=DecisionTreeClassifier, seed=SEED, parametros=dt_params)\n",
    "\n",
    "grad_boost = SklearnPadre(clasif=GradientBoostingClassifier, seed=SEED, parametros=gb_params)\n",
    "\n",
    "bag_log_reg = SklearnPadre(clasif=BaggingClassifier, seed=SEED, parametros=bag_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output de los modelos de primer nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realizamos las predicciones para el set de entrenamiento y el test final con OOF. Estos resultados base serán utilizados como input en el modelo de segundo nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_total = time()\n",
    "\n",
    "# Random Forest\n",
    "t0_rf = time()\n",
    "rf_oof_train, rf_oof_test = get_oof(random_forest, x, y, x_test_final)\n",
    "tf_rf = time() - t0_rf\n",
    "print (\"Tiempo de entrenamiento del random forest: %0.5f seconds.\" % tf_rf)\n",
    "\n",
    "# Extra Trees\n",
    "t0_et = time()\n",
    "et_oof_train, et_oof_test = get_oof(extra_trees, x, y, x_test_final)\n",
    "tf_et = time() - t0_et\n",
    "print (\"Tiempo de entrenamiento del extra trees: %0.5f seconds.\" % tf_et)\n",
    "\n",
    "# Decision Tree\n",
    "t0_dt = time()\n",
    "dt_oof_train, dt_oof_test = get_oof(decision_tree, x, y, x_test_final)\n",
    "tf_dt = time() - t0_dt\n",
    "print (\"Tiempo de entrenamiento del decision tree: %0.5f seconds.\" % tf_dt)\n",
    "\n",
    "# Gradient Boosting\n",
    "t0_gb = time()\n",
    "gb_oof_train, gb_oof_test = get_oof(grad_boost, x, y, x_test_final)\n",
    "tf_gb = time() - t0_gb\n",
    "print (\"Tiempo de entrenamiento del gradient boosting: %0.5f seconds.\" % tf_gb)\n",
    "\n",
    "# Bagging con Logistic Regresion\n",
    "t0_bag = time()\n",
    "bag_oof_train, bag_oof_test = get_oof(bag_log_reg, x, y, x_test_final)\n",
    "tf_bag = time() - t0_bag\n",
    "print (\"Tiempo de entrenamiento del bagging con logistic regression: %0.5f seconds.\" % tf_bag)\n",
    "\n",
    "# Tiempo total de ejecución\n",
    "tf_total = time() - t0_total\n",
    "print (\"Tiempo total de entrenamiento del modelo de 1er nivel: %0.5f seconds.\" % tf_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de los features en base a los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_features = random_forest.feature_importances(x,y)\n",
    "\n",
    "et_features = extra_trees.feature_importances(x,y)\n",
    "\n",
    "dt_features = decision_tree.feature_importances(x,y)\n",
    "\n",
    "gb_features = grad_boost.feature_importances(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ACA HAY QUE COPIAR Y PEGAR LA SALIDA DE ARRIBA PERO EN FORMATO ARRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un dataframe con la importancia de cada feature para cada clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "\n",
    "df_features = pd.DataFrame({'Features': features,\\\n",
    "                            'Random Forest': rf_features,\\\n",
    "                            'Extra Trees': et_features,\\\n",
    "                            'Decision Tree': dt_features,\\\n",
    "                            'Gradient Boost': gb_features,\\\n",
    "                            })\n",
    "\n",
    "df_features = df_features[['Features', 'Random Forest', 'Extra Trees', 'Decision Tree', 'Gradient Boost']]\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: plotear el df de arriba. Podría ser un heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos una columna contenedora del promedio de la importancia del feature para todos los clasificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['promedio'] = df_features.mean(axis=1)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de 2do Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos las predicciones obtenidas en el modelo de primer nivel como input del siguiente modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, analizamos las predicciones del primer nivel para cada clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones_primer_nivel = pd.DataFrame({'Random Forest': rf_oof_train.ravel(),\\\n",
    "                                          'Extra Trees': et_oof_train.ravel(),\\\n",
    "                                          'Decision Tree': dt_oof_train.ravel(),\\\n",
    "                                          'Gradient Boosting': gb_oof_train.ravel(),\\\n",
    "                                          'Bagging con LogReg': bag_oof_train.ravel()\\\n",
    "                                          })\n",
    "predicciones_primer_nivel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlación de los clasificadores del modelo de 1er nivel (set de entrenamiento del modelo de 2do nivel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: tirar un heatmap con predicciones_primer_nivel.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos las predicciones obtenidas en el modelo de 1er nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2do_nivel = np.concatenate((et_oof_train, rf_oof_train, ab_oof_train, gb_oof_train, bag_oof_train), axis=1)\n",
    "\n",
    "x_test_final_2do_nivel = np.concatenate((et_oof_test, rf_oof_test, ab_oof_test, gb_oof_test, bag_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos XGBoost para el modelo de 2do nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con el set de entrenamiento obtenido en el modelo de 1er nivel\n",
    "xgboost.fit(x_2do_nivel, y)\n",
    "\n",
    "# Realizamos las predicciones con el set definitivo\n",
    "pred_final = gbm.predict(x_test_final_2do_nivel)\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicciones con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "\n",
    "# Creamos el xgboost\n",
    "xgboost = xgb.XGBClassifier(learning_rate = 0.02,\\\n",
    "                            n_estimators= 2000,\\\n",
    "                            max_depth= 5,\\\n",
    "                            min_child_weight= 2,\\\n",
    "                            gamma=0.9,\\                        \n",
    "                            subsample=0.7,\\\n",
    "                            colsample_bytree=0.7,\\\n",
    "                            objective= 'binary:logistic',\\\n",
    "                            nthread= -1,\\\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con el set de entrenamiento obtenido en el modelo de 1er nivel\n",
    "xgboost.fit(x_2do_nivel, y)\n",
    "\n",
    "# Realizamos las predicciones con el set definitivo\n",
    "pred_final_proba = gbm.predict_proba(x_test_final_2do_nivel)\n",
    "\n",
    "# Nos quedamos con la columna correspondiente de probabilidades\n",
    "df_predicciones = pd.DataFrame(pred_final_proba)\n",
    "pred_final_proba = np.array(df_predicciones[1])\n",
    "\n",
    "tf = time() - t0\n",
    "print (\"Tiempo de ejecución: %0.5f seconds.\" % tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con valores binarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "submit.to_csv('submits/submit_ensamble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['sepostulo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit con probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_proba = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final_proba})\n",
    "submit_proba.to_csv('submits/submit_ensamble_proba.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no = submit_proba['sepostulo'] < 0.5\n",
    "si = submit_proba['sepostulo'] >= 0.5\n",
    "\n",
    "cant_no = submit_proba.loc[(no)].count()\n",
    "cant_si = submit_proba.loc[(si)].count()\n",
    "\n",
    "print(\"0   \", cant_no[1])\n",
    "print(\"1   \", cant_si[1])\n",
    "print(\"Name: sepostulo, dtype: int64\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
