{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importación de Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "# import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#import plotly.offline as py\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier,\\\n",
    "                             GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set de Entrenamiento y Test Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('modelo.csv')\n",
    "test_final = pd.read_csv('test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = train['se_postulo'] == 1\n",
    "no = train['se_postulo'] == 0\n",
    "\n",
    "train_si = train[si].sample(200000)\n",
    "train_no = train[no].sample(200000)\n",
    "\n",
    "train_final = pd.merge(train_si, train_no, how='outer')\n",
    "\n",
    "x_train = np.array(train_final[['sexo', 'orden_estudio', 'tipo_de_trabajo', 'nivel_laboral']])\n",
    "y_train = np.array(train_final['se_postulo'])\n",
    "\n",
    "x_test = np.array(test_final[['sexo', 'orden_estudio', 'tipo_de_trabajo', 'nivel_laboral']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la Correlación de Pearson entre los distintos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap de la Correlación de Pearson\n",
    "# colormap = plt.cm.RdBu\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.title('Features - Correlación de Pearson', y=1.05, size=15)\n",
    "# sns.heatmap(train.astype(float).corr(),linewidths=0.1,vmax=1.0, \n",
    "#            square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Definición de algunas variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_aviso_postulante = test_final['id']\n",
    "\n",
    "ntrain = x_train.shape[0] # Cantidad de registros totales del set de entrenamiento\n",
    "\n",
    "ntest = x_test.shape[0] # Cantidad de registros totales del set de pruebas\n",
    "\n",
    "SEED = 0 # Seed\n",
    "\n",
    "NFOLDS = 5 # Cantidad de bloques a particionar para KFold\n",
    "\n",
    "kfold = KFold(ntrain, n_folds=NFOLDS, random_state=SEED) # KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de la clase SklearnPadre\n",
    "Lo que realizamos a continuación es la creación de una clase que posee los métodos comunes de los clasificadores de Sklearn que utilizaremos en el presente trabajo. De esta forma, ahorramos líneas de código y evitamos redundancia a la hora de utilizar los métodos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El inicializador recibe un clasificador de Sklearn, un seed y los parámetros necesarios del clasificador en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnPadre(object):\n",
    "    def __init__(self, clasif, seed=0, parametros=None):\n",
    "        parametros['random_state'] = seed\n",
    "        self.clasif = clasif(**parametros)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clasif.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clasif.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.clasif.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self, x, y):\n",
    "        print(self.clasif.fit(x,y).feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones OOF (Out Of Fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLICAR UN POCO PARA QUÉ SIRVE ESTA FUNCIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clasif, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros(ntrain)\n",
    "    oof_test = np.zeros(ntest)\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kfold):\n",
    "        x_train_i = x_train[train_index]\n",
    "        y_train_i = y_train[train_index]\n",
    "        x_test_i = x_train[test_index]\n",
    "\n",
    "        clasif.train(x_train_i, y_train_i)\n",
    "\n",
    "        oof_train[test_index] = clasif.predict(x_test_i)\n",
    "        oof_test_skf[i, :] = clasif.predict(x_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    \n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Primer Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación llevaremos a cabo nuestro primer nivel de clasificación mediante el uso de algunos clasificadores de la librería Sklearn:\n",
    "\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- Adaptive Boosting\n",
    "- Gradient Boosting\n",
    "- SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de los hiper-parámetros necesarios para cada algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RANDOM FOREST'''\n",
    "# n_estimators      --> cantidad de árboles en el random forest\n",
    "# max_features      --> cant_maxima de features a considerar antes de realizar un split\n",
    "# max_depth         --> profundidad máxima del árbol\n",
    "# min_samples_split --> minimo de muestras necesario para realizar un split\n",
    "# min_samples_leaf  --> minimo de muestras necesario para que se trate de un nodo hoja\n",
    "# oof_score         --> True si se utilizan las muestras OOB para estimar la precisión\n",
    "# n_jobs            --> -1 = numero de cores (para correr en paralelo fit y predict)\n",
    "# warm_start        --> True si se utiliza la solución previa del fit y añade más estimadores al ensamble\n",
    "rf_params = {'n_estimators': 100,\n",
    "             'max_features': 'sqrt',\n",
    "             'max_depth': 5,\n",
    "             'min_samples_split': 2,\n",
    "             'min_samples_leaf': 2,\n",
    "             'bootstrap': True,\n",
    "             'oob_score': True,\n",
    "             'n_jobs': -1,\n",
    "             'warm_start': True\n",
    "             }\n",
    "\n",
    "\n",
    "'''EXTRA TREES'''\n",
    "et_params = {'n_estimators': 100,\n",
    "             'max_features': 'sqrt',\n",
    "             'max_depth': 5,\n",
    "             'min_samples_split': 2,\n",
    "             'min_samples_leaf': 2,\n",
    "             'bootstrap': True,\n",
    "             'oob_score': True,\n",
    "             'n_jobs': -1,\n",
    "             'warm_start': True\n",
    "             }\n",
    "\n",
    "\n",
    "'''ADAPTIVE BOOSTING'''\n",
    "# learning_rate --> en cuánto se reduce la tasa de contribución de cada clasificador\n",
    "ab_params = {'n_estimators': 100,\n",
    "             'learning_rate': 0.75\n",
    "             }\n",
    "\n",
    "\n",
    "'''GRADIENT BOOSTING'''\n",
    "gb_params = {'learning_rate': 0.1,\n",
    "             'n_estimators': 100,\n",
    "             'max_depth': 4,\n",
    "             'min_samples_split': 2,\n",
    "             'min_samples_leaf': 2,\n",
    "             'max_features': 'sqrt',\n",
    "             'warm_start': True \n",
    "             }\n",
    "\n",
    "\n",
    "'''SVM'''\n",
    "# C      --> costo por clasificar mal un punto\n",
    "# kernel --> kernel a utilizar en el algoritmo\n",
    "# gamma  --> parámetro gamma para el kernel RBF\n",
    "svm_params = {'C': 0.5,\n",
    "              'kernel': 'rbf',\n",
    "              'gamma': 'auto'\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los clasificadores según los hiper-parámetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = SklearnPadre(clasif=RandomForestClassifier, seed=SEED, parametros=rf_params)\n",
    "\n",
    "extra_trees = SklearnPadre(clasif=ExtraTreesClassifier, seed=SEED, parametros=et_params)\n",
    "\n",
    "ada_boost = SklearnPadre(clasif=AdaBoostClassifier, seed=SEED, parametros=ab_params)\n",
    "\n",
    "grad_boost = SklearnPadre(clasif=GradientBoostingClassifier, seed=SEED, parametros=gb_params)\n",
    "\n",
    "svm = SklearnPadre(clasif=SVC, seed=SEED, parametros=svm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output de los modelos de primer nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones del set de entrenamiento y de pruebas con OOF.\n",
    "# Estos resultados base serán utilizados como nuevos features en el modelo de segundo nivel.\n",
    "rf_oof_train, rf_oof_test = get_oof(random_forest,x_train, y_train, x_test)\n",
    "\n",
    "et_oof_train, et_oof_test = get_oof(extra_trees, x_train, y_train, x_test)\n",
    "\n",
    "ab_oof_train, ab_oof_test = get_oof(ada_boost, x_train, y_train, x_test) \n",
    "\n",
    "gb_oof_train, gb_oof_test = get_oof(grad_boost,x_train, y_train, x_test)\n",
    "\n",
    "svm_oof_train, svm_oof_test = get_oof(svm,x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de los features en base a los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07031283 0.18288966 0.38535799 0.36143952]\n",
      "[0.24012803 0.08902858 0.50766786 0.16317553]\n",
      "[0.03 0.33 0.53 0.11]\n",
      "[0.09563239 0.30288287 0.28617408 0.31531066]\n"
     ]
    }
   ],
   "source": [
    "rf_features = random_forest.feature_importances(x_train,y_train)\n",
    "\n",
    "et_features = extra_trees.feature_importances(x_train, y_train)\n",
    "\n",
    "ab_features = ada_boost.feature_importances(x_train, y_train)\n",
    "\n",
    "gb_features = grad_boost.feature_importances(x_train,y_train)\n",
    "\n",
    "# Creo que deberiamos agregar svm_features = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACA HAY QUE COPIAR Y PEGAR LA SALIDA DE ARRIBA PERO EN FORMATO ARRAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de un dataframe con la importancia de los features para cada clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>Adaptive Boost</th>\n",
       "      <th>Gradient Boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orden_estudio</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tipo_de_trabajo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nivel_laboral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Features Random Forest Extra Trees Adaptive Boost Gradient Boost\n",
       "0             sexo          None        None           None           None\n",
       "1    orden_estudio          None        None           None           None\n",
       "2  tipo_de_trabajo          None        None           None           None\n",
       "3    nivel_laboral          None        None           None           None"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas = np.array(['sexo', 'orden_estudio', 'tipo_de_trabajo', 'nivel_laboral'])\n",
    "\n",
    "df_features = pd.DataFrame({'Features': columnas,\n",
    "                            'Random Forest': rf_features,\n",
    "                            'Extra Trees': et_features,\n",
    "                            'Adaptive Boost': ab_features,\n",
    "                            'Gradient Boost': gb_features\n",
    "                            })\n",
    "\n",
    "df_features = df_features[['Features', 'Random Forest', 'Extra Trees', 'Adaptive Boost', 'Gradient Boost']]\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de la importancia de los features para cada clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIRAR ACA UN PAR DE PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos una columna contenedora del promedio de la importancia de los features de cada fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>Adaptive Boost</th>\n",
       "      <th>Gradient Boost</th>\n",
       "      <th>promedio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orden_estudio</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tipo_de_trabajo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nivel_laboral</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Features Random Forest Extra Trees Adaptive Boost Gradient Boost  \\\n",
       "0             sexo          None        None           None           None   \n",
       "1    orden_estudio          None        None           None           None   \n",
       "2  tipo_de_trabajo          None        None           None           None   \n",
       "3    nivel_laboral          None        None           None           None   \n",
       "\n",
       "   promedio  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  \n",
       "3       NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features['promedio'] = df_features.mean(axis=1)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización del promedio de la importancia los features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIRAR ACA UN PAR DE PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Segundo Nivel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos las predicciones obtenidas en el modelo de primer nivel como input del siguiente modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, analizamos las predicciones del primer nivel para cada clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adaptive Boosting</th>\n",
       "      <th>Extra Trees</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adaptive Boosting  Extra Trees  Gradient Boosting  Random Forest\n",
       "0                1.0          1.0                1.0            1.0\n",
       "1                1.0          0.0                0.0            0.0\n",
       "2                0.0          0.0                0.0            0.0\n",
       "3                0.0          0.0                0.0            0.0\n",
       "4                0.0          1.0                1.0            1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones_primer_nivel = pd.DataFrame({'Random Forest': rf_oof_train.ravel(),\n",
    "                                          'Extra Trees': et_oof_train.ravel(),\n",
    "                                          'Adaptive Boosting': ab_oof_train.ravel(),\n",
    "                                          'Gradient Boosting': gb_oof_train.ravel()\n",
    "                                          })\n",
    "predicciones_primer_nivel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenamos las predicciones obtenidas en el primer nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2 = np.concatenate((et_oof_train, rf_oof_train, ab_oof_train, gb_oof_train, svm_oof_train), axis=1)\n",
    "\n",
    "x_test_2 = np.concatenate((et_oof_test, rf_oof_test, ab_oof_test, gb_oof_test, svm_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos XGBoost para el modelo de segundo nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Creamos el xgboost\\nxgboost = xgb.XGBClassifier(\\n                            learning_rate = 0.02,\\n                            n_estimators= 1000,\\n                            max_depth= 5,\\n                            min_child_weight= 2,\\n                            gamma=0.9,                        \\n                            subsample=0.7,\\n                            colsample_bytree=0.7,\\n                            objective= 'binary:logistic',\\n                            nthread= -1,\\n                            scale_pos_weight=1)\\n\\n# Lo entrenamos con el set de entrenamiento\\nxgboost.fit(x_train_2, y_train)\\n\\n# Realizamos las predicciones con el set de pruebas\\npredicciones_segundo_nivel = gbm.predict(x_test_2)\\n\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos el xgboost\n",
    "'''\n",
    "xgboost = xgb.XGBClassifier(\n",
    "                            learning_rate = 0.02,\n",
    "                            n_estimators= 1000,\n",
    "                            max_depth= 5,\n",
    "                            min_child_weight= 2,\n",
    "                            gamma=0.9,                        \n",
    "                            subsample=0.7,\n",
    "                            colsample_bytree=0.7,\n",
    "                            objective= 'binary:logistic',\n",
    "                            nthread= -1,\n",
    "                            scale_pos_weight=1)\n",
    "\n",
    "# Lo entrenamos con el set de entrenamiento obtenido en el modelo de primer nivel\n",
    "xgboost.fit(x_train_2, y_train)\n",
    "\n",
    "# Realizamos las predicciones con el set definitivo\n",
    "pred_final = gbm.predict(x_test_2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(x_train_2, y_train)\n",
    "\n",
    "pred_final = perceptron.predict(x_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de haber entrenado y ajustado nuestros modelos de primer y segundo nivel, predecimos el test file definitivo correspondiente a la competencia de Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'id':id_aviso_postulante, 'sepostulo':pred_final})\n",
    "\n",
    "submit.to_csv('submit_ensamble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
